{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"g_AYZVlLBlWX"},"outputs":[],"source":["#direct the path to google drive directory\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bfvNKqJrBrWp"},"outputs":[],"source":["#import all libraries\n","import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import glob\n","import os\n","import imageio\n","import cv2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PJPmYgryB1Kl"},"outputs":[],"source":["path = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/without_mask/\"\n","path2 = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/without_final/\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OGjySSXaB7C9"},"outputs":[],"source":["#use pre-trained cascade classifier to detect the faces (without masks)\n","count = 0\n","for i in range(1000, 2000):\n","  img = cv2.imread(path+'seed'+str(i)+'.png')\n","  face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n","  faces = face_engine.detectMultiScale(img,scaleFactor=1.3,minNeighbors=5)\n","  for (x,y,w,h) in faces:\n","    cropped = img[y:y+h, x:x+w]\n","    pic2 = cv2.resize(cropped, (128,128), interpolation=cv2.INTER_AREA)\n","    cv2.imwrite(path2 + str(count) + \".png\", pic2)\n","    count = count + 1\n","  print(path+'seed'+str(i)+'.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w8b06SS0Cr8K"},"outputs":[],"source":["import glob\n","import os"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28716,"status":"ok","timestamp":1634056683519,"user":{"displayName":"William Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2R-GIHVc_oJsiMUuN3jWE2xSwNaVJZ7GuHF-G=s64","userId":"16664965966693979153"},"user_tz":-480},"id":"M5e8C0RUXYn5","outputId":"aa0d199d-c542-4bb1-f23f-861569b76a8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cjdmioBuXa6q"},"outputs":[],"source":["WSI_MASK_PATH = '/content/drive/MyDrive/STATS302_FINAL_PROJECT/00000'#存放图片的文件夹路径\n","file_names = glob.glob(os.path.join(WSI_MASK_PATH, '*.jpg'))\n","file_names.sort()\n","file_names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ur-EZQwIXknE"},"outputs":[],"source":["#use pre-trained cascade classifier to detect the faces wearing masks incorrectly\n","import cv2\n","path3 = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/00000\"\n","path4 = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/incorrect_final/\"\n","\n","count = 0\n","for i in range(0, 1000):\n","  img = cv2.imread(file_names[i])\n","  face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n","  faces = face_engine.detectMultiScale(img,scaleFactor=1.3,minNeighbors=5)\n","  for (x,y,w,h) in faces:\n","    cropped = img[y:y+h, x:x+w]\n","    pic2 = cv2.resize(cropped, (128,128), interpolation=cv2.INTER_AREA)\n","    cv2.imwrite(path4 + str(count) + \".png\", pic2)\n","    count = count + 1\n","  print(file_names[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qfmIu2rRYU_Z"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Face Detection.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.4"}},"nbformat":4,"nbformat_minor":0}
