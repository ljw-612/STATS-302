{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Face Detection.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"g_AYZVlLBlWX"},"source":["#direct the path to google drive directory\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bfvNKqJrBrWp"},"source":["#import all libraries\n","import pandas as pd\n","import numpy as np \n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import glob\n","import os\n","import imageio\n","import cv2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"PJPmYgryB1Kl"},"source":["path = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/without_mask/\"\n","path2 = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/without_final/\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OGjySSXaB7C9"},"source":["#use pre-trained cascade classifier to detect the faces (without masks)\n","count = 0\n","for i in range(1000, 2000):\n","  img = cv2.imread(path+'seed'+str(i)+'.png')\n","  face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n","  faces = face_engine.detectMultiScale(img,scaleFactor=1.3,minNeighbors=5)\n","  for (x,y,w,h) in faces:\n","    cropped = img[y:y+h, x:x+w]\n","    pic2 = cv2.resize(cropped, (128,128), interpolation=cv2.INTER_AREA)\n","    cv2.imwrite(path2 + str(count) + \".png\", pic2)\n","    count = count + 1\n","  print(path+'seed'+str(i)+'.png')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"w8b06SS0Cr8K"},"source":["import glob\n","import os"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"M5e8C0RUXYn5","executionInfo":{"status":"ok","timestamp":1634056683519,"user_tz":-480,"elapsed":28716,"user":{"displayName":"William Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gi2R-GIHVc_oJsiMUuN3jWE2xSwNaVJZ7GuHF-G=s64","userId":"16664965966693979153"}},"outputId":"aa0d199d-c542-4bb1-f23f-861569b76a8f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"id":"cjdmioBuXa6q"},"source":["WSI_MASK_PATH = '/content/drive/MyDrive/STATS302_FINAL_PROJECT/00000'#存放图片的文件夹路径\n","file_names = glob.glob(os.path.join(WSI_MASK_PATH, '*.jpg'))\n","file_names.sort()\n","file_names"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ur-EZQwIXknE"},"source":["#use pre-trained cascade classifier to detect the faces wearing masks incorrectly\n","import cv2\n","path3 = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/00000\"\n","path4 = \"/content/drive/MyDrive/STATS302_FINAL_PROJECT/incorrect_final/\"\n","\n","count = 0\n","for i in range(0, 1000):\n","  img = cv2.imread(file_names[i])\n","  face_engine = cv2.CascadeClassifier(cv2.data.haarcascades+'haarcascade_frontalface_default.xml')\n","  faces = face_engine.detectMultiScale(img,scaleFactor=1.3,minNeighbors=5)\n","  for (x,y,w,h) in faces:\n","    cropped = img[y:y+h, x:x+w]\n","    pic2 = cv2.resize(cropped, (128,128), interpolation=cv2.INTER_AREA)\n","    cv2.imwrite(path4 + str(count) + \".png\", pic2)\n","    count = count + 1\n","  print(file_names[i])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qfmIu2rRYU_Z"},"source":[""],"execution_count":null,"outputs":[]}]}