{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uxYjwG63c8t"
      },
      "source": [
        "#import all necessary libraries for the project\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.svm import SVC"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSRepPLV7yFI",
        "outputId": "620390ab-d809-4e62-a5d6-3846da22ec25"
      },
      "source": [
        "#direct the path to the google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbDPaJ-q8Kgy"
      },
      "source": [
        "path1='drive/MyDrive/STATS302_FINAL_PROJECT'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kW6R0ynz9BzA",
        "outputId": "1aa505d1-5e5d-4cde-ce54-fc9b5840832e"
      },
      "source": [
        "data=pd.read_csv(path1+'/final_label_2.csv')\n",
        "data['tag'].unique()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 2, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohV2kVjL9Q5-",
        "outputId": "a21342a5-5af2-43c6-fd1f-2c61826b9c8e"
      },
      "source": [
        "#convert the label to a numpy array\n",
        "label=np.array(data['tag'])\n",
        "ylabel=label.reshape(2087,1)\n",
        "ylabel"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1],\n",
              "       [2],\n",
              "       [1],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wg68bY69-ogf"
      },
      "source": [
        "path_original = \"drive/MyDrive/STATS302_FINAL_PROJECT/final_segment_images\"\n",
        "path_without = \"drive/MyDrive/STATS302_FINAL_PROJECT/without_final\"\n",
        "path_incorrect = \"drive/MyDrive/STATS302_FINAL_PROJECT/incorrect_final\""
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brQ5fQm7_D_d"
      },
      "source": [
        "#designate the paths for all images\n",
        "path1 = glob.glob(os.path.join(path_original, '*.png'))\n",
        "path1\n",
        "\n",
        "path2 = glob.glob(os.path.join(path_without, '*.png'))\n",
        "path2\n",
        "path = path1 + path2\n",
        "\n",
        "path3 = glob.glob(os.path.join(path_incorrect, '*.png'))\n",
        "path3\n",
        "path = path + path3"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15RRzWTC_OxP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0835bf71-4bca-4c7b-babc-3f664a80adb3"
      },
      "source": [
        "#create the matrix for all images\n",
        "img_list = []\n",
        "# img = cv2.imread(path[0])\n",
        "# img\n",
        "for file in path:\n",
        "  img = cv2.imread(file)\n",
        "  img = (img/255.0)\n",
        "  img_list.append(img)\n",
        "img_list = np.array(img_list)\n",
        "img_list"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[[0.14509804, 0.12941176, 0.1254902 ],\n",
              "         [0.14509804, 0.12941176, 0.1254902 ],\n",
              "         [0.14509804, 0.12941176, 0.1254902 ],\n",
              "         ...,\n",
              "         [0.15294118, 0.14117647, 0.14901961],\n",
              "         [0.15294118, 0.14117647, 0.14901961],\n",
              "         [0.15294118, 0.14117647, 0.14901961]],\n",
              "\n",
              "        [[0.14509804, 0.12941176, 0.1254902 ],\n",
              "         [0.14509804, 0.12941176, 0.1254902 ],\n",
              "         [0.14509804, 0.12941176, 0.1254902 ],\n",
              "         ...,\n",
              "         [0.15294118, 0.14117647, 0.14901961],\n",
              "         [0.15294118, 0.14117647, 0.14901961],\n",
              "         [0.15294118, 0.14117647, 0.14901961]],\n",
              "\n",
              "        [[0.14509804, 0.12941176, 0.1254902 ],\n",
              "         [0.14509804, 0.12941176, 0.1254902 ],\n",
              "         [0.14509804, 0.12941176, 0.1254902 ],\n",
              "         ...,\n",
              "         [0.14901961, 0.1372549 , 0.14509804],\n",
              "         [0.14901961, 0.1372549 , 0.14509804],\n",
              "         [0.14901961, 0.1372549 , 0.14509804]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.29803922, 0.28627451, 0.34509804],\n",
              "         [0.29803922, 0.28627451, 0.34509804],\n",
              "         [0.29803922, 0.28627451, 0.34509804],\n",
              "         ...,\n",
              "         [0.24313725, 0.22745098, 0.2745098 ],\n",
              "         [0.24313725, 0.22745098, 0.2745098 ],\n",
              "         [0.24313725, 0.22745098, 0.2745098 ]],\n",
              "\n",
              "        [[0.29803922, 0.28627451, 0.34509804],\n",
              "         [0.29803922, 0.28627451, 0.34509804],\n",
              "         [0.29803922, 0.28627451, 0.34509804],\n",
              "         ...,\n",
              "         [0.24313725, 0.22745098, 0.2745098 ],\n",
              "         [0.24313725, 0.22745098, 0.2745098 ],\n",
              "         [0.24313725, 0.22745098, 0.2745098 ]],\n",
              "\n",
              "        [[0.29803922, 0.28627451, 0.34509804],\n",
              "         [0.29803922, 0.28627451, 0.34509804],\n",
              "         [0.29803922, 0.28627451, 0.34509804],\n",
              "         ...,\n",
              "         [0.24313725, 0.22745098, 0.2745098 ],\n",
              "         [0.24313725, 0.22745098, 0.2745098 ],\n",
              "         [0.24313725, 0.22745098, 0.2745098 ]]],\n",
              "\n",
              "\n",
              "       [[[0.2745098 , 0.20392157, 0.2       ],\n",
              "         [0.2745098 , 0.20392157, 0.2       ],\n",
              "         [0.2745098 , 0.20392157, 0.2       ],\n",
              "         ...,\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235]],\n",
              "\n",
              "        [[0.2745098 , 0.20392157, 0.2       ],\n",
              "         [0.2745098 , 0.20392157, 0.2       ],\n",
              "         [0.2745098 , 0.20392157, 0.2       ],\n",
              "         ...,\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235]],\n",
              "\n",
              "        [[0.2627451 , 0.2       , 0.19215686],\n",
              "         [0.2627451 , 0.2       , 0.19215686],\n",
              "         [0.2627451 , 0.2       , 0.19215686],\n",
              "         ...,\n",
              "         [0.10588235, 0.09803922, 0.09803922],\n",
              "         [0.10588235, 0.09803922, 0.09803922],\n",
              "         [0.10588235, 0.09803922, 0.09803922]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.11764706, 0.10980392, 0.10980392],\n",
              "         [0.11764706, 0.10980392, 0.10980392],\n",
              "         [0.11764706, 0.10980392, 0.10980392],\n",
              "         ...,\n",
              "         [0.09411765, 0.09411765, 0.09411765],\n",
              "         [0.09411765, 0.09411765, 0.09411765],\n",
              "         [0.09411765, 0.09411765, 0.09411765]],\n",
              "\n",
              "        [[0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         ...,\n",
              "         [0.09803922, 0.09803922, 0.09803922],\n",
              "         [0.09803922, 0.09803922, 0.09803922],\n",
              "         [0.09803922, 0.09803922, 0.09803922]],\n",
              "\n",
              "        [[0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         [0.11372549, 0.10588235, 0.10588235],\n",
              "         ...,\n",
              "         [0.09803922, 0.09803922, 0.09803922],\n",
              "         [0.09803922, 0.09803922, 0.09803922],\n",
              "         [0.09803922, 0.09803922, 0.09803922]]],\n",
              "\n",
              "\n",
              "       [[[0.58431373, 0.49411765, 0.70588235],\n",
              "         [0.58431373, 0.49411765, 0.70588235],\n",
              "         [0.58431373, 0.49411765, 0.70588235],\n",
              "         ...,\n",
              "         [0.14901961, 0.14509804, 0.15294118],\n",
              "         [0.14901961, 0.14509804, 0.15294118],\n",
              "         [0.14901961, 0.14509804, 0.15294118]],\n",
              "\n",
              "        [[0.58431373, 0.49411765, 0.70588235],\n",
              "         [0.58431373, 0.49411765, 0.70588235],\n",
              "         [0.58431373, 0.49411765, 0.70588235],\n",
              "         ...,\n",
              "         [0.14901961, 0.14509804, 0.15294118],\n",
              "         [0.14901961, 0.14509804, 0.15294118],\n",
              "         [0.14901961, 0.14509804, 0.15294118]],\n",
              "\n",
              "        [[0.58431373, 0.49411765, 0.70588235],\n",
              "         [0.58431373, 0.49411765, 0.70588235],\n",
              "         [0.58431373, 0.49411765, 0.70588235],\n",
              "         ...,\n",
              "         [0.14901961, 0.14509804, 0.15294118],\n",
              "         [0.14901961, 0.14509804, 0.15294118],\n",
              "         [0.14901961, 0.14509804, 0.15294118]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.35294118, 0.30588235, 0.2627451 ],\n",
              "         [0.35294118, 0.30588235, 0.2627451 ],\n",
              "         [0.35294118, 0.30588235, 0.2627451 ],\n",
              "         ...,\n",
              "         [0.14509804, 0.16862745, 0.38823529],\n",
              "         [0.14509804, 0.16862745, 0.38823529],\n",
              "         [0.14509804, 0.16862745, 0.38823529]],\n",
              "\n",
              "        [[0.35294118, 0.30588235, 0.2627451 ],\n",
              "         [0.35294118, 0.30588235, 0.2627451 ],\n",
              "         [0.35294118, 0.30588235, 0.2627451 ],\n",
              "         ...,\n",
              "         [0.14509804, 0.16862745, 0.38823529],\n",
              "         [0.14509804, 0.16862745, 0.38823529],\n",
              "         [0.14509804, 0.16862745, 0.38823529]],\n",
              "\n",
              "        [[0.35294118, 0.30588235, 0.2627451 ],\n",
              "         [0.35294118, 0.30588235, 0.2627451 ],\n",
              "         [0.35294118, 0.30588235, 0.2627451 ],\n",
              "         ...,\n",
              "         [0.14509804, 0.16862745, 0.38823529],\n",
              "         [0.14509804, 0.16862745, 0.38823529],\n",
              "         [0.14509804, 0.16862745, 0.38823529]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0.78823529, 0.79215686, 0.78823529],\n",
              "         [0.78823529, 0.78431373, 0.78823529],\n",
              "         [0.78039216, 0.78431373, 0.78431373],\n",
              "         ...,\n",
              "         [0.10196078, 0.15686275, 0.17254902],\n",
              "         [0.30588235, 0.36078431, 0.36078431],\n",
              "         [0.52941176, 0.55294118, 0.55686275]],\n",
              "\n",
              "        [[0.78823529, 0.78823529, 0.78823529],\n",
              "         [0.78431373, 0.78823529, 0.78431373],\n",
              "         [0.76470588, 0.76862745, 0.76862745],\n",
              "         ...,\n",
              "         [0.09019608, 0.14509804, 0.16470588],\n",
              "         [0.1254902 , 0.18823529, 0.20784314],\n",
              "         [0.43529412, 0.48627451, 0.49411765]],\n",
              "\n",
              "        [[0.79215686, 0.78823529, 0.78431373],\n",
              "         [0.77254902, 0.78431373, 0.77254902],\n",
              "         [0.74117647, 0.75294118, 0.74901961],\n",
              "         ...,\n",
              "         [0.10196078, 0.14509804, 0.16078431],\n",
              "         [0.10588235, 0.15686275, 0.19215686],\n",
              "         [0.22745098, 0.28627451, 0.30980392]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.76470588, 0.76470588, 0.76470588],\n",
              "         [0.76470588, 0.76470588, 0.76470588],\n",
              "         [0.76862745, 0.76862745, 0.76862745],\n",
              "         ...,\n",
              "         [0.11372549, 0.0627451 , 0.40784314],\n",
              "         [0.10196078, 0.05490196, 0.39215686],\n",
              "         [0.09803922, 0.05490196, 0.39607843]],\n",
              "\n",
              "        [[0.76470588, 0.76470588, 0.76470588],\n",
              "         [0.76470588, 0.76470588, 0.76470588],\n",
              "         [0.76862745, 0.76470588, 0.76470588],\n",
              "         ...,\n",
              "         [0.10980392, 0.05098039, 0.39607843],\n",
              "         [0.10980392, 0.05882353, 0.4       ],\n",
              "         [0.08627451, 0.05098039, 0.38431373]],\n",
              "\n",
              "        [[0.76470588, 0.76470588, 0.76470588],\n",
              "         [0.76470588, 0.76470588, 0.76470588],\n",
              "         [0.76470588, 0.76470588, 0.76470588],\n",
              "         ...,\n",
              "         [0.09411765, 0.04705882, 0.35294118],\n",
              "         [0.09411765, 0.04705882, 0.36470588],\n",
              "         [0.08627451, 0.04705882, 0.35294118]]],\n",
              "\n",
              "\n",
              "       [[[0.47843137, 0.55294118, 0.69019608],\n",
              "         [0.48235294, 0.56078431, 0.69803922],\n",
              "         [0.47843137, 0.55686275, 0.70196078],\n",
              "         ...,\n",
              "         [0.30980392, 0.35686275, 0.47058824],\n",
              "         [0.24705882, 0.29411765, 0.39607843],\n",
              "         [0.15294118, 0.20784314, 0.30588235]],\n",
              "\n",
              "        [[0.48235294, 0.56078431, 0.69411765],\n",
              "         [0.48235294, 0.56078431, 0.70196078],\n",
              "         [0.49019608, 0.56078431, 0.70588235],\n",
              "         ...,\n",
              "         [0.29411765, 0.3372549 , 0.43921569],\n",
              "         [0.32156863, 0.37254902, 0.4627451 ],\n",
              "         [0.22745098, 0.2627451 , 0.34509804]],\n",
              "\n",
              "        [[0.48235294, 0.56078431, 0.70588235],\n",
              "         [0.48627451, 0.56078431, 0.70588235],\n",
              "         [0.48627451, 0.56078431, 0.70588235],\n",
              "         ...,\n",
              "         [0.36470588, 0.41176471, 0.48235294],\n",
              "         [0.32156863, 0.36470588, 0.45490196],\n",
              "         [0.31372549, 0.36470588, 0.4745098 ]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.23921569, 0.34117647, 0.59215686],\n",
              "         [0.21568627, 0.32156863, 0.58039216],\n",
              "         [0.18039216, 0.29411765, 0.56470588],\n",
              "         ...,\n",
              "         [0.40392157, 0.49411765, 0.69803922],\n",
              "         [0.41960784, 0.50588235, 0.70588235],\n",
              "         [0.43137255, 0.52156863, 0.70980392]],\n",
              "\n",
              "        [[0.22745098, 0.3372549 , 0.58823529],\n",
              "         [0.20784314, 0.31764706, 0.57254902],\n",
              "         [0.17647059, 0.29803922, 0.55294118],\n",
              "         ...,\n",
              "         [0.39215686, 0.49019608, 0.70196078],\n",
              "         [0.41176471, 0.50196078, 0.70588235],\n",
              "         [0.42745098, 0.51764706, 0.70980392]],\n",
              "\n",
              "        [[0.21960784, 0.32941176, 0.59215686],\n",
              "         [0.2       , 0.30588235, 0.57254902],\n",
              "         [0.16862745, 0.28627451, 0.55294118],\n",
              "         ...,\n",
              "         [0.38039216, 0.47843137, 0.70588235],\n",
              "         [0.40392157, 0.49803922, 0.70588235],\n",
              "         [0.42352941, 0.51764706, 0.70588235]]],\n",
              "\n",
              "\n",
              "       [[[0.18823529, 0.23529412, 0.32156863],\n",
              "         [0.18823529, 0.23529412, 0.31764706],\n",
              "         [0.18823529, 0.23529412, 0.31764706],\n",
              "         ...,\n",
              "         [0.11764706, 0.16470588, 0.25098039],\n",
              "         [0.09803922, 0.15294118, 0.23137255],\n",
              "         [0.09019608, 0.14509804, 0.22352941]],\n",
              "\n",
              "        [[0.16470588, 0.21960784, 0.30588235],\n",
              "         [0.16470588, 0.21960784, 0.30588235],\n",
              "         [0.16078431, 0.21568627, 0.30588235],\n",
              "         ...,\n",
              "         [0.1372549 , 0.18823529, 0.2627451 ],\n",
              "         [0.1254902 , 0.17254902, 0.25098039],\n",
              "         [0.11372549, 0.16078431, 0.23921569]],\n",
              "\n",
              "        [[0.14117647, 0.19607843, 0.28627451],\n",
              "         [0.14509804, 0.2       , 0.29019608],\n",
              "         [0.14117647, 0.19607843, 0.28627451],\n",
              "         ...,\n",
              "         [0.15686275, 0.2       , 0.2745098 ],\n",
              "         [0.14509804, 0.18431373, 0.2627451 ],\n",
              "         [0.13333333, 0.17647059, 0.25490196]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0.01960784, 0.08235294, 0.26666667],\n",
              "         [0.01568627, 0.08235294, 0.26666667],\n",
              "         [0.01960784, 0.08627451, 0.2745098 ],\n",
              "         ...,\n",
              "         [0.1254902 , 0.10980392, 0.05490196],\n",
              "         [0.12156863, 0.10980392, 0.05490196],\n",
              "         [0.1254902 , 0.10980392, 0.05882353]],\n",
              "\n",
              "        [[0.01960784, 0.08235294, 0.26666667],\n",
              "         [0.01568627, 0.08235294, 0.26666667],\n",
              "         [0.01568627, 0.08627451, 0.27058824],\n",
              "         ...,\n",
              "         [0.1372549 , 0.11764706, 0.05882353],\n",
              "         [0.13333333, 0.11764706, 0.05882353],\n",
              "         [0.12941176, 0.11372549, 0.05882353]],\n",
              "\n",
              "        [[0.01960784, 0.08235294, 0.26666667],\n",
              "         [0.01960784, 0.08235294, 0.2627451 ],\n",
              "         [0.01960784, 0.08627451, 0.2627451 ],\n",
              "         ...,\n",
              "         [0.14117647, 0.1254902 , 0.06666667],\n",
              "         [0.14117647, 0.12156863, 0.0627451 ],\n",
              "         [0.13333333, 0.11764706, 0.0627451 ]]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRTSU9azAPGF",
        "outputId": "c60ae48f-a70c-43ef-b726-c282267869d4"
      },
      "source": [
        "img_list.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2087, 128, 128, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmHN1UBpAh5E",
        "outputId": "816290b1-d435-4557-cde8-068f0d703da7"
      },
      "source": [
        "#count the distinct variables\n",
        "(unique, counts) = np.unique(ylabel, return_counts=True)\n",
        "\n",
        "frequencies = np.asarray((unique, counts)).T\n",
        "\n",
        "print (frequencies)\n",
        "print (len(unique))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  0 536]\n",
            " [  1 821]\n",
            " [  2 730]]\n",
            "3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hP54pRbWA2hZ"
      },
      "source": [
        "#define different categories\n",
        "class_types=['incorrect_wear','with_mask','without_mask']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlZ3tjRVDV0-",
        "outputId": "43cfa3e4-7c97-4660-f56b-71ab107a006f"
      },
      "source": [
        "#convert all variables to dummy variables\n",
        "train_lab_categorical = tf.keras.utils.to_categorical(\n",
        "    ylabel, num_classes=3, dtype='uint8')\n",
        "print(train_lab_categorical)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0]\n",
            " [0 0 1]\n",
            " [0 1 0]\n",
            " ...\n",
            " [1 0 0]\n",
            " [1 0 0]\n",
            " [1 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pak-ZNKCDc0T",
        "outputId": "686a20e3-5f8e-49f0-9b8d-eaeecab128e9"
      },
      "source": [
        "#split training set and test set (for both orginal labels and dummied labels)\n",
        "from sklearn.model_selection import train_test_split \n",
        "train_im, test_im, train_lab, test_lab = train_test_split(img_list, train_lab_categorical, test_size=0.3, \n",
        "                                                            stratify=train_lab_categorical,\n",
        "                                                            random_state=100, shuffle = True)\n",
        "train_im2, test_im2, train_lab2, test_lab2 = train_test_split(img_list, ylabel, test_size=0.20,                                                            \n",
        "                                                            random_state=40, shuffle = True)\n",
        "print (\"train data shape after the split: \", train_im.shape)\n",
        "print ('new test data shape: ', test_im.shape)\n",
        "print (\"test labels shape: \", test_lab.shape)\n",
        "train_lab"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train data shape after the split:  (1460, 128, 128, 3)\n",
            "new test data shape:  (627, 128, 128, 3)\n",
            "test labels shape:  (627, 3)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 1],\n",
              "       [0, 1, 0],\n",
              "       [0, 1, 0],\n",
              "       ...,\n",
              "       [0, 1, 0],\n",
              "       [1, 0, 0],\n",
              "       [0, 1, 0]], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "25Xh2dY_NT-C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GNZnhz7Fze_"
      },
      "source": [
        "#import necessary libraries for the dataset\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, ZeroPadding2D,\\\n",
        "     Flatten, BatchNormalization, AveragePooling2D, Dense, Activation, Add \n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import activations\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras import regularizers"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36PsNYJzF4Mi"
      },
      "source": [
        "##### Include Little Data Augmentation \n",
        "batch_size = 64 # try several values\n",
        "\n",
        "train_DataGen = tf.keras.preprocessing.image.ImageDataGenerator(zoom_range=0.2, \n",
        "                                                                width_shift_range=0.1, \n",
        "                                                                height_shift_range = 0.1, \n",
        "                                                                horizontal_flip=True)\n",
        " \n",
        "valid_datagen = tf.keras.preprocessing.image.ImageDataGenerator()\n",
        "\n",
        "train_set_conv = train_DataGen.flow(train_im, train_lab, batch_size=batch_size) # train_lab is categorical \n",
        "valid_set_conv = valid_datagen.flow(test_im, test_lab, batch_size=batch_size) # so as valid_lab "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QtUvGWVGCiK"
      },
      "source": [
        "#define identity unit for the network\n",
        "def res_identity(x, filters): \n",
        "\n",
        "  x_skip = x # this will be used for addition with the residual block \n",
        "  f1, f2 = filters\n",
        "\n",
        "  #first block \n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #second block # bottleneck (but size kept same with padding)\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  # third block activation used after adding the input\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  # x = Activation(activations.relu)(x)\n",
        "\n",
        "  # add the input \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1PxKMsIYGIRM"
      },
      "source": [
        "#define convolutionary layers\n",
        "def res_conv(x, s, filters):\n",
        "\n",
        "  x_skip = x\n",
        "  f1, f2 = filters\n",
        "\n",
        "  # first block\n",
        "  x = Conv2D(f1, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  # when s = 2 then it is like downsizing the feature map\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  # second block\n",
        "  x = Conv2D(f1, kernel_size=(3, 3), strides=(1, 1), padding='same', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  #third block\n",
        "  x = Conv2D(f2, kernel_size=(1, 1), strides=(1, 1), padding='valid', kernel_regularizer=l2(0.001))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # shortcut \n",
        "  x_skip = Conv2D(f2, kernel_size=(1, 1), strides=(s, s), padding='valid', kernel_regularizer=l2(0.001))(x_skip)\n",
        "  x_skip = BatchNormalization()(x_skip)\n",
        "\n",
        "  # add \n",
        "  x = Add()([x, x_skip])\n",
        "  x = Activation(activations.relu)(x)\n",
        "\n",
        "  return x"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyDYfHv6GL6y"
      },
      "source": [
        "### Combine the above functions to build 50 layers resnet. \n",
        "def resnet50():\n",
        "\n",
        "  input_im = Input(shape=(train_im.shape[1], train_im.shape[2], train_im.shape[3])) # cifar 10 images size\n",
        "  x = ZeroPadding2D(padding=(3, 3))(input_im)\n",
        "\n",
        "  # 1st stage\n",
        "  # here we perform maxpooling, see the figure above\n",
        "\n",
        "  x = Conv2D(64, kernel_size=(7, 7), strides=(2, 2))(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation(activations.relu)(x)\n",
        "  x = MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
        "\n",
        "  #2nd stage \n",
        "  # frm here on only conv block and identity block, no pooling\n",
        "\n",
        "  x = res_conv(x, s=1, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "  x = res_identity(x, filters=(64, 256))\n",
        "\n",
        "  # 3rd stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "  x = res_identity(x, filters=(128, 512))\n",
        "\n",
        "  # 4th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "  x = res_identity(x, filters=(256, 1024))\n",
        "\n",
        "  # 5th stage\n",
        "\n",
        "  x = res_conv(x, s=2, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "  x = res_identity(x, filters=(512, 2048))\n",
        "\n",
        "  # ends with average pooling and dense connection\n",
        "\n",
        "  x = AveragePooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "  x = Flatten()(x)\n",
        "\n",
        "  x = Dense(len(class_types),activation='softmax',kernel_initializer='he_normal',kernel_regularizer=regularizers.l2(0.01),\n",
        "                activity_regularizer=regularizers.l1(0.01))(x)\n",
        "\n",
        "  model = Model(inputs=input_im, outputs=x, name='Resnet50')\n",
        "\n",
        "  return model"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hdYppmMGSUG"
      },
      "source": [
        "### Define some Callbacks\n",
        "def lrdecay(epoch):\n",
        "    lr = 1e-3\n",
        "    if epoch > 180:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 160:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 120:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 80:\n",
        "        lr *= 1e-1\n",
        "    #print('Learning rate: ', lr)\n",
        "    return lr\n",
        "  # if epoch < 40:\n",
        "  #   return 0.01\n",
        "  # else:\n",
        "  #   return 0.01 * np.math.exp(0.03 * (40 - epoch))\n",
        "lrdecay = tf.keras.callbacks.LearningRateScheduler(lrdecay) # learning rate decay  \n",
        "\n",
        "\n",
        "def earlystop(mode):\n",
        "  if mode=='acc':\n",
        "    estop = tf.keras.callbacks.EarlyStopping(monitor='val_acc', patience=15, mode='max')\n",
        "  elif mode=='loss':\n",
        "    estop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=15, mode='min')\n",
        "  return estop    "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTkko3unGWyj"
      },
      "source": [
        "resnet50_model = resnet50()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XI93fgv6GhHE",
        "outputId": "41fd4be0-0f0a-4a78-9304-2b7b75b6f6cb"
      },
      "source": [
        "#show the structure of the network\n",
        "resnet50_model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"Resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "zero_padding2d (ZeroPadding2D)  (None, 134, 134, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 64, 64, 64)   9472        zero_padding2d[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64, 64, 64)   256         conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 64, 64, 64)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 31, 31, 64)   0           activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 31, 31, 64)   4160        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 31, 31, 64)   256         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 31, 31, 64)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 31, 31, 64)   36928       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 31, 31, 64)   256         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 31, 31, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 31, 31, 256)  16640       activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 31, 31, 256)  16640       max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 31, 31, 256)  1024        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 31, 31, 256)  1024        conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add (Add)                       (None, 31, 31, 256)  0           batch_normalization_3[0][0]      \n",
            "                                                                 batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 31, 31, 256)  0           add[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 31, 31, 64)   16448       activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 31, 31, 64)   256         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 31, 31, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 31, 31, 64)   36928       activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 31, 31, 64)   256         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 31, 31, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 31, 31, 256)  16640       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 31, 31, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 31, 31, 256)  0           batch_normalization_7[0][0]      \n",
            "                                                                 activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 31, 31, 256)  0           add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 31, 31, 64)   16448       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 31, 31, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 31, 31, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 31, 31, 64)   36928       activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 31, 31, 64)   256         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 31, 31, 64)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 31, 31, 256)  16640       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 31, 31, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 31, 31, 256)  0           batch_normalization_10[0][0]     \n",
            "                                                                 activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 31, 31, 256)  0           add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 16, 16, 128)  32896       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 128)  512         conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 128)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 128)  147584      activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 128)  512         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 128)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  66048       activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 512)  131584      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 16, 16, 512)  2048        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
            "                                                                 batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 512)  0           add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 128)  65664       activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 16, 16, 128)  512         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 128)  147584      activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 16, 16, 128)  512         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 16, 16, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 16, 16, 512)  66048       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 16, 16, 512)  2048        conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 16, 16, 512)  0           batch_normalization_17[0][0]     \n",
            "                                                                 activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 16, 16, 512)  0           add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 16, 16, 128)  65664       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 16, 16, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 16, 16, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 16, 16, 128)  147584      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 16, 16, 128)  512         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 16, 16, 128)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 16, 16, 512)  66048       activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 16, 16, 512)  2048        conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 512)  0           batch_normalization_20[0][0]     \n",
            "                                                                 activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 16, 16, 512)  0           add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 16, 16, 128)  65664       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 16, 16, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 16, 16, 128)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 16, 16, 128)  147584      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 16, 16, 128)  512         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 16, 16, 128)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 16, 16, 512)  66048       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 512)  2048        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 512)  0           batch_normalization_23[0][0]     \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 16, 16, 512)  0           add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 8, 8, 256)    131328      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 8, 8, 256)    1024        conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 8, 8, 256)    0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 8, 8, 256)    590080      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 8, 8, 256)    1024        conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 8, 8, 256)    0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 8, 8, 1024)   263168      activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 8, 8, 1024)   525312      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 8, 8, 1024)   4096        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 8, 8, 1024)   4096        conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_26[0][0]     \n",
            "                                                                 batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 8, 8, 1024)   0           add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 8, 8, 256)    262400      activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 8, 8, 256)    1024        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 8, 8, 256)    0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 8, 8, 256)    590080      activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 8, 8, 256)    1024        conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 8, 8, 256)    0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 8, 8, 1024)   263168      activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 8, 8, 1024)   4096        conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_30[0][0]     \n",
            "                                                                 activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 8, 8, 1024)   0           add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 8, 8, 256)    262400      activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 8, 8, 256)    1024        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 8, 8, 256)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 8, 8, 256)    590080      activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 8, 8, 256)    1024        conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 8, 8, 256)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 8, 8, 1024)   263168      activation_29[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 8, 8, 1024)   4096        conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 8, 8, 1024)   0           batch_normalization_33[0][0]     \n",
            "                                                                 activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 8, 8, 1024)   0           add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 8, 8, 256)    262400      activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 8, 8, 256)    1024        conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 8, 8, 256)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 8, 8, 256)    590080      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 8, 8, 256)    1024        conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 8, 8, 256)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 8, 8, 1024)   263168      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 8, 8, 1024)   4096        conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_36[0][0]     \n",
            "                                                                 activation_30[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 8, 8, 1024)   0           add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 8, 8, 256)    262400      activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 8, 8, 256)    1024        conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 8, 8, 256)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 8, 8, 256)    590080      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 8, 8, 256)    1024        conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 8, 8, 256)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 8, 8, 1024)   263168      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 8, 8, 1024)   4096        conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_39[0][0]     \n",
            "                                                                 activation_33[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 8, 8, 1024)   0           add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 8, 8, 256)    262400      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 8, 8, 256)    1024        conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 8, 8, 256)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 8, 8, 256)    590080      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 8, 8, 256)    1024        conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 8, 8, 256)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 8, 8, 1024)   263168      activation_38[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 8, 8, 1024)   4096        conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 8, 8, 1024)   0           batch_normalization_42[0][0]     \n",
            "                                                                 activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 8, 8, 1024)   0           add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 4, 4, 512)    524800      activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 4, 4, 512)    2048        conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 4, 4, 512)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 4, 4, 512)    2359808     activation_40[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 4, 4, 512)    2048        conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 4, 4, 512)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 4, 4, 2048)   1050624     activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 4, 4, 2048)   2099200     activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 4, 4, 2048)   8192        conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 4, 4, 2048)   8192        conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_13 (Add)                    (None, 4, 4, 2048)   0           batch_normalization_45[0][0]     \n",
            "                                                                 batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 4, 4, 2048)   0           add_13[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 4, 4, 512)    1049088     activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 4, 4, 512)    2048        conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 4, 4, 512)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 4, 4, 512)    2359808     activation_43[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 4, 4, 512)    2048        conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 4, 4, 512)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 4, 4, 2048)   1050624     activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 4, 4, 2048)   8192        conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_14 (Add)                    (None, 4, 4, 2048)   0           batch_normalization_49[0][0]     \n",
            "                                                                 activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 4, 4, 2048)   0           add_14[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 4, 4, 512)    1049088     activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 4, 4, 512)    2048        conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 4, 4, 512)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 4, 4, 512)    2359808     activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 4, 4, 512)    2048        conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 4, 4, 512)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 4, 4, 2048)   1050624     activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 4, 4, 2048)   8192        conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "add_15 (Add)                    (None, 4, 4, 2048)   0           batch_normalization_52[0][0]     \n",
            "                                                                 activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 4, 4, 2048)   0           add_15[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 2, 2, 2048)   0           activation_48[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8192)         0           average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 3)            24579       flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 23,612,291\n",
            "Trainable params: 23,559,171\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwHDHsY7Gjqy"
      },
      "source": [
        "#add optimizer, loss function and quality metrics to the model.\n",
        "resnet50_model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=1e-4), \n",
        "                       metrics=['acc'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-ZSSKtmGo-Z",
        "outputId": "7de37ca1-b0f4-4817-d895-21c2512be9f6"
      },
      "source": [
        "#Run the model\n",
        "batch_size=batch_size \n",
        "\n",
        "resnet_train = resnet50_model.fit(train_set_conv, \n",
        "                                  epochs=40, \n",
        "                                  steps_per_epoch=train_im.shape[0]/batch_size, \n",
        "                                  validation_steps=test_im.shape[0]/batch_size, \n",
        "                                  validation_data=valid_set_conv,\n",
        "                                  callbacks=[lrdecay])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "22/22 [==============================] - 346s 15s/step - loss: 20.7957 - acc: 0.6877 - val_loss: 19.4361 - val_acc: 0.3509\n",
            "Epoch 2/40\n",
            "22/22 [==============================] - 339s 15s/step - loss: 18.4019 - acc: 0.9041 - val_loss: 19.1397 - val_acc: 0.3493\n",
            "Epoch 3/40\n",
            "22/22 [==============================] - 338s 15s/step - loss: 17.4199 - acc: 0.9295 - val_loss: 17.9314 - val_acc: 0.3493\n",
            "Epoch 4/40\n",
            "22/22 [==============================] - 339s 15s/step - loss: 16.4370 - acc: 0.9301 - val_loss: 17.1459 - val_acc: 0.3493\n",
            "Epoch 5/40\n",
            "22/22 [==============================] - 338s 15s/step - loss: 15.3745 - acc: 0.9363 - val_loss: 15.8627 - val_acc: 0.3573\n",
            "Epoch 6/40\n",
            "22/22 [==============================] - 338s 15s/step - loss: 14.3526 - acc: 0.9411 - val_loss: 15.0378 - val_acc: 0.3493\n",
            "Epoch 7/40\n",
            "22/22 [==============================] - 338s 15s/step - loss: 13.3557 - acc: 0.9507 - val_loss: 13.9796 - val_acc: 0.3493\n",
            "Epoch 8/40\n",
            "22/22 [==============================] - 338s 15s/step - loss: 12.4395 - acc: 0.9493 - val_loss: 13.1352 - val_acc: 0.3509\n",
            "Epoch 9/40\n",
            "22/22 [==============================] - 339s 15s/step - loss: 11.5660 - acc: 0.9445 - val_loss: 12.0626 - val_acc: 0.4147\n",
            "Epoch 10/40\n",
            "22/22 [==============================] - 340s 15s/step - loss: 10.7969 - acc: 0.9452 - val_loss: 11.2642 - val_acc: 0.5056\n",
            "Epoch 11/40\n",
            "22/22 [==============================] - 339s 15s/step - loss: 10.0350 - acc: 0.9521 - val_loss: 10.9875 - val_acc: 0.3636\n",
            "Epoch 12/40\n",
            "22/22 [==============================] - 340s 15s/step - loss: 9.3776 - acc: 0.9521 - val_loss: 9.8796 - val_acc: 0.6459\n",
            "Epoch 13/40\n",
            "22/22 [==============================] - 340s 15s/step - loss: 8.7504 - acc: 0.9582 - val_loss: 9.4275 - val_acc: 0.4274\n",
            "Epoch 14/40\n",
            "22/22 [==============================] - 342s 15s/step - loss: 8.2235 - acc: 0.9514 - val_loss: 8.7132 - val_acc: 0.6220\n",
            "Epoch 15/40\n",
            "22/22 [==============================] - 342s 15s/step - loss: 7.7235 - acc: 0.9514 - val_loss: 8.6368 - val_acc: 0.4928\n",
            "Epoch 16/40\n",
            "22/22 [==============================] - 343s 15s/step - loss: 7.2576 - acc: 0.9507 - val_loss: 7.7173 - val_acc: 0.6635\n",
            "Epoch 17/40\n",
            "22/22 [==============================] - 340s 15s/step - loss: 6.8576 - acc: 0.9438 - val_loss: 7.0679 - val_acc: 0.7528\n",
            "Epoch 18/40\n",
            "22/22 [==============================] - 341s 15s/step - loss: 6.4609 - acc: 0.9534 - val_loss: 6.8855 - val_acc: 0.6667\n",
            "Epoch 19/40\n",
            "22/22 [==============================] - 341s 15s/step - loss: 6.0858 - acc: 0.9548 - val_loss: 6.5802 - val_acc: 0.6475\n",
            "Epoch 20/40\n",
            "22/22 [==============================] - 342s 15s/step - loss: 5.7500 - acc: 0.9637 - val_loss: 6.2480 - val_acc: 0.6427\n",
            "Epoch 21/40\n",
            "22/22 [==============================] - 341s 15s/step - loss: 5.4482 - acc: 0.9658 - val_loss: 5.8614 - val_acc: 0.7257\n",
            "Epoch 22/40\n",
            "22/22 [==============================] - 341s 15s/step - loss: 5.1909 - acc: 0.9541 - val_loss: 5.2438 - val_acc: 0.8963\n",
            "Epoch 23/40\n",
            "22/22 [==============================] - 342s 15s/step - loss: 5.1633 - acc: 0.9178 - val_loss: 27279.5762 - val_acc: 0.2568\n",
            "Epoch 24/40\n",
            "22/22 [==============================] - 343s 15s/step - loss: 5.2012 - acc: 0.9274 - val_loss: 838.2947 - val_acc: 0.2679\n",
            "Epoch 25/40\n",
            "22/22 [==============================] - 343s 15s/step - loss: 4.9738 - acc: 0.9425 - val_loss: 10.4591 - val_acc: 0.7129\n",
            "Epoch 26/40\n",
            "22/22 [==============================] - 345s 15s/step - loss: 4.6864 - acc: 0.9473 - val_loss: 4.6084 - val_acc: 0.9426\n",
            "Epoch 27/40\n",
            "22/22 [==============================] - 345s 15s/step - loss: 4.4515 - acc: 0.9534 - val_loss: 4.5835 - val_acc: 0.9123\n",
            "Epoch 28/40\n",
            "22/22 [==============================] - 343s 15s/step - loss: 4.2805 - acc: 0.9493 - val_loss: 4.4522 - val_acc: 0.9490\n",
            "Epoch 29/40\n",
            "22/22 [==============================] - 343s 15s/step - loss: 4.2774 - acc: 0.9527 - val_loss: 38.8250 - val_acc: 0.4242\n",
            "Epoch 30/40\n",
            "22/22 [==============================] - 342s 15s/step - loss: 4.2498 - acc: 0.9212 - val_loss: 1373.1384 - val_acc: 0.2568\n",
            "Epoch 31/40\n",
            "22/22 [==============================] - 342s 15s/step - loss: 4.1332 - acc: 0.9158 - val_loss: 80.4123 - val_acc: 0.2775\n",
            "Epoch 32/40\n",
            "22/22 [==============================] - 345s 15s/step - loss: 3.8675 - acc: 0.9452 - val_loss: 9.8985 - val_acc: 0.4242\n",
            "Epoch 33/40\n",
            "22/22 [==============================] - 356s 16s/step - loss: 3.6923 - acc: 0.9425 - val_loss: 4.7654 - val_acc: 0.6045\n",
            "Epoch 34/40\n",
            "22/22 [==============================] - 352s 15s/step - loss: 3.5226 - acc: 0.9445 - val_loss: 3.8740 - val_acc: 0.7863\n",
            "Epoch 35/40\n",
            "22/22 [==============================] - 356s 16s/step - loss: 3.3566 - acc: 0.9568 - val_loss: 3.5854 - val_acc: 0.8612\n",
            "Epoch 36/40\n",
            "22/22 [==============================] - 348s 15s/step - loss: 3.2292 - acc: 0.9548 - val_loss: 3.3883 - val_acc: 0.8820\n",
            "Epoch 37/40\n",
            "22/22 [==============================] - 343s 15s/step - loss: 3.1201 - acc: 0.9568 - val_loss: 3.2192 - val_acc: 0.9203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfgfK6AD-6rM"
      },
      "source": [
        "#extract the last dense layer from the trained models\n",
        "representation_model = Model(inputs=resnet50_model.inputs, outputs=resnet50_model.get_layer('flatten').output)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghq3mACp-7PS"
      },
      "source": [
        "#apply the layer to every ovservation\n",
        "representation_model_output = representation_model.predict(train_im2)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q-zJ7uDNBn7W",
        "outputId": "30974f07-759e-4940-f1b5-36f83e01e811"
      },
      "source": [
        "representation_model_output.shape"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1669, 8192)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOyfBMoqSvnh"
      },
      "source": [
        "representation_model_output_test = representation_model.predict(test_im2)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1e6batR3Bo9e"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "svm=SVC(kernel='rbf',C=0.1)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBF8A1TfSlpi"
      },
      "source": [
        "#from sklearn.decomposition import PCA\n",
        "#pca=PCA(n_components=2)\n",
        "#train_PCA=pca.fit_transform(representation_model_output)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a16_pUDCSrwt",
        "outputId": "5131bf20-ae5f-44b4-d4cc-3b358cd25b52"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "#test_PCA=pca.fit_transform(representation_model_output_test)\n",
        "svm.fit(representation_model_output,train_lab2)\n",
        "predicts=svm.predict(representation_model_output_test)\n",
        "accuracy_score(test_lab2,predicts)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9425837320574163"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WYEtyt61sPD",
        "outputId": "2c691244-c011-49f7-c570-4591a84a666b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#construct the confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "matrix = confusion_matrix(test_lab2, predicts)\n",
        "matrix"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[100,   4,   3],\n",
              "       [  6, 140,   3],\n",
              "       [  6,   2, 154]])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJ2uUyv62gMd"
      },
      "source": [
        "#define a funcation that could draw confusion matrix\n",
        "def plot_confusion_matrix(cm, labels_name, title):\n",
        "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]   \n",
        "    plt.imshow(cm, interpolation='nearest')   \n",
        "    plt.title(title)    \n",
        "    plt.colorbar()\n",
        "    num_local = np.array(range(len(labels_name)))    \n",
        "    plt.xticks(num_local, labels_name, rotation=90)    \n",
        "    plt.yticks(num_local, labels_name)    \n",
        "    plt.ylabel('True label')    \n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srmwGOMT2lg2",
        "outputId": "2ad5b803-20ce-47aa-dfcd-17cde2c58d37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        }
      },
      "source": [
        "#draw the confusion matrix plot\n",
        "plot_confusion_matrix(matrix, class_types, \"Confusion Matrix\")\n",
        "# plt.savefig('/HAR_cm.png', format='png')\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yPnFgNR2rxs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}