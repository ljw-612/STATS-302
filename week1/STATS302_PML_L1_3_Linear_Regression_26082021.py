# -*- coding: utf-8 -*-
"""STATS302-PML-L1-3-Linear-Regression-26082021

Automatically generated by Colaboratory.
"""

import numpy as np
import matplotlib.pyplot as plt


## load data
def load_data(data_file, separator = ','):

  data_2D = np.genfromtxt(data_file, delimiter = separator, names = True)

  x_label = data_2D.dtype.names[0] ## only feature name
  y_label = data_2D.dtype.names[1] ## only output / label name

  print(x_label, " -- ", y_label)

  x = data_2D[ x_label ] ## feature values for all the data points
  y = data_2D[ y_label ] ## output / label values for all the data points

  num_data = len( data_2D )

  return x, y, x_label, y_label, num_data

## gradient descent
def gradient_descent(x, y, num_data, num_iter = 50, alpha = 0.00001):

  theta0 = 0
  theta1 = 0

  theta0_values = []
  theta1_values = []

  MSE = 0  ## mean squared error
  MAE = 0  ## mean absolute error

  MSE_values = []
  MAE_values = []

  h = 0

  ## let's optimize for theta0 and theta1
  for i in range(num_iter):

    ## prediction function
    ## so the predicted values for all the data points
    h = theta0 + theta1 * x

    ## after derivation
    theta0 = theta0 - alpha * ( 1 / num_data ) * sum( h - y )
    theta1 = theta1 - alpha * ( 1 / num_data ) * sum( ( h - y ) * x )

    theta0_values.append( theta0 )
    theta1_values.append( theta1 )

    print('#', i, " -- theta0 = ", theta0, ", theta1 = ", theta1)

    ## ignoring 1/2
    MSE = sum( (h  - y)**2 ) / num_data

    MAE = sum( abs(h - y) ) / num_data

    print("MSE = ", MSE, " -- MAE = ", MAE)

    MSE_values.append( MSE )
    MAE_values.append( MAE )


  return h, theta0_values, theta1_values, MSE_values, MAE_values




## run
def run(data_file, num_iter, alpha):

  x, y, x_label, y_label, num_data = load_data(data_file)

  visualize_data(x, y, x_label, y_label)

  ## gradient descent
  h, theta0_values, theta1_values, MSE_values, MAE_values = gradient_descent(x, y, num_data, num_iter, alpha)



  ## show results


## main
if __name__ == '__main__':

  data_file = 'm2-house-prices-univariate-data.csv'
  num_iter = 500   ## number of optimization steps hyper-parameter 
  alpha = 0.000001 ## default:0.00001 -- learning rate hyper-parameter

  run(data_file, num_iter, alpha)
